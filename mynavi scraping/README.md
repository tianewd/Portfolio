# **目的**

スクレイピングの一連の流れを行うこと

# **背景**

転職活動中に、Python求人が関西では極端に少なく、首都圏に集中していることを知り、可視化したいと思い始めた。

また、業種未経験と経験者で給料がどの程度が変わるのかも合わせて確認する。

# **概要**

１．検索条件を指定したマイナビ転職サイトのURLを準備する（詳細は別記）

２．HTML形式で全ページ保存する

３．保存したHTMLファイルを開き、年収と会社名を取得、DataFrameに格納する

４．各検索条件ごとのボックスプロットを表示する

# 使用ソフト

・Anaconda Navigator 2.3.1 (anaconda3)

・Visual Studio Code 1.65.0

・Python　

# python version

・Python	3.8.13　　　

・numpy		1.18.5

・pandas    1.5.1

・matplotlib    3.5.1

・japanize-matplotlib     1.1.3

・beautifulsoup4    4.11.1

・requests  2.28.1

# 実行する際に

ファイルを実行する際はフォルダを作成し、以下ファイルを同じフォルダに入れて、実行してください
・ipynbファイル1つ

# 実行データ

**mynavi.ipynb**

# 1．検索条件（場所、業種未経験）を設定する

検索したい条件以外をコメント化する（Windows：Ctrl + /）

今回、準備した検索条件は以下の4つ
・#関西x業種未経験

・首都圏x業種未経験

・関西x経験者（特定の検索条件なし）

・首都圏x経験者（特定の検索条件なし）

※URL詳細：https://tenshoku.mynavi.jp/{where}{pa}kwpython/only/

where : shutoken => 首都圏       kansai => 関西

pa : /list/pa1/ => 業種未経験       /list/ => 経験者

*kwpythonのkw以下で検索キーワードを変更できる　（例） kwjava => javaでキーワード検索

# 2．HTML形式で全ページ保存する

1ページ目から総案件数を取得し、ページ数を計算する。

※ページ数計算詳細：50件/ページで、50で割り切れなかった分を+1ページとする。

（例）237件 => 237/50=4あまり37 => 5ページ

ページごとにをHTML形式でファイル保存する。

# 3．保存したHTMLファイルを開き、年収と会社名を取得、DataFrameに格納する

各求人のテーブルを取得し、最低年収を抽出する。
（例）初年度の年収：320～600万円 => 320

年収の記載がある求人情報だけ、会社名を抽出する。
（例）システムズ株式会社 | 自社開発パッケージも～ => システムズ株式会社

年収と会社名をDataFrameに格納する。
（例）・首都圏x業種未経験 => shutoken_pa1_df

# 4．各検索条件ごとのボックスプロットを表示する

各検索条件ごとのボックスプロットを表示する。

グラフにデータ数、平均値、標準偏差値も併記する。

